{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9eb3043-70ea-43de-b9dc-80eeff105fe6",
   "metadata": {},
   "source": [
    "## imports required for this testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bc45861-5943-4f4b-bc33-8d47554bc7e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import random\n",
    "from xgboost import XGBClassifier\n",
    "from scipy.stats import gamma\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd961769-b272-47a5-b7ed-6247aa7d306f",
   "metadata": {},
   "source": [
    "## Importing data and processing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c967919f-564e-42d1-9140-9d451cc6c5b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc</th>\n",
       "      <th>v(g)</th>\n",
       "      <th>ev(g)</th>\n",
       "      <th>iv(g)</th>\n",
       "      <th>n</th>\n",
       "      <th>v</th>\n",
       "      <th>l</th>\n",
       "      <th>d</th>\n",
       "      <th>i</th>\n",
       "      <th>e</th>\n",
       "      <th>...</th>\n",
       "      <th>lOCode</th>\n",
       "      <th>lOComment</th>\n",
       "      <th>lOBlank</th>\n",
       "      <th>locCodeAndComment</th>\n",
       "      <th>uniq_Op</th>\n",
       "      <th>uniq_Opnd</th>\n",
       "      <th>total_Op</th>\n",
       "      <th>total_Opnd</th>\n",
       "      <th>branchCount</th>\n",
       "      <th>defects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>309.13</td>\n",
       "      <td>0.11</td>\n",
       "      <td>9.50</td>\n",
       "      <td>32.54</td>\n",
       "      <td>2936.77</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>215.49</td>\n",
       "      <td>0.06</td>\n",
       "      <td>16.00</td>\n",
       "      <td>13.47</td>\n",
       "      <td>3447.89</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>346.13</td>\n",
       "      <td>0.06</td>\n",
       "      <td>17.33</td>\n",
       "      <td>19.97</td>\n",
       "      <td>5999.58</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    loc  v(g)  ev(g)  iv(g)     n       v     l      d      i        e  ...  \\\n",
       "0   1.1   1.4    1.4    1.4   1.3    1.30  1.30   1.30   1.30     1.30  ...   \n",
       "1   1.0   1.0    1.0    1.0   1.0    1.00  1.00   1.00   1.00     1.00  ...   \n",
       "2  24.0   5.0    1.0    3.0  63.0  309.13  0.11   9.50  32.54  2936.77  ...   \n",
       "3  20.0   4.0    4.0    2.0  47.0  215.49  0.06  16.00  13.47  3447.89  ...   \n",
       "4  24.0   6.0    6.0    2.0  72.0  346.13  0.06  17.33  19.97  5999.58  ...   \n",
       "\n",
       "   lOCode  lOComment  lOBlank  locCodeAndComment  uniq_Op  uniq_Opnd  \\\n",
       "0       2          2        2                  2      1.2        1.2   \n",
       "1       1          1        1                  1      1.0        1.0   \n",
       "2       1          0        6                  0     15.0       15.0   \n",
       "3       0          0        3                  0     16.0        8.0   \n",
       "4       0          0        3                  0     16.0       12.0   \n",
       "\n",
       "   total_Op  total_Opnd  branchCount  defects  \n",
       "0       1.2         1.2          1.4    False  \n",
       "1       1.0         1.0          1.0     True  \n",
       "2      44.0        19.0          9.0    False  \n",
       "3      31.0        16.0          7.0    False  \n",
       "4      46.0        26.0         11.0    False  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"D:/RUAS/SEM_8/Project/Material/DATASET/CM1.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24d18393-8a95-4c6d-b65d-d3d119b5afae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df.drop(['defects'], axis=1)\n",
    "y = df['defects']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77a192b7-1d3e-4cfa-a9ce-3de0c8648370",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc</th>\n",
       "      <th>v(g)</th>\n",
       "      <th>ev(g)</th>\n",
       "      <th>iv(g)</th>\n",
       "      <th>n</th>\n",
       "      <th>v</th>\n",
       "      <th>l</th>\n",
       "      <th>d</th>\n",
       "      <th>i</th>\n",
       "      <th>e</th>\n",
       "      <th>...</th>\n",
       "      <th>t</th>\n",
       "      <th>lOCode</th>\n",
       "      <th>lOComment</th>\n",
       "      <th>lOBlank</th>\n",
       "      <th>locCodeAndComment</th>\n",
       "      <th>uniq_Op</th>\n",
       "      <th>uniq_Opnd</th>\n",
       "      <th>total_Op</th>\n",
       "      <th>total_Opnd</th>\n",
       "      <th>branchCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>...</td>\n",
       "      <td>1.30</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>309.13</td>\n",
       "      <td>0.11</td>\n",
       "      <td>9.50</td>\n",
       "      <td>32.54</td>\n",
       "      <td>2936.77</td>\n",
       "      <td>...</td>\n",
       "      <td>163.15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>215.49</td>\n",
       "      <td>0.06</td>\n",
       "      <td>16.00</td>\n",
       "      <td>13.47</td>\n",
       "      <td>3447.89</td>\n",
       "      <td>...</td>\n",
       "      <td>191.55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>346.13</td>\n",
       "      <td>0.06</td>\n",
       "      <td>17.33</td>\n",
       "      <td>19.97</td>\n",
       "      <td>5999.58</td>\n",
       "      <td>...</td>\n",
       "      <td>333.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>47.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>1563.78</td>\n",
       "      <td>0.04</td>\n",
       "      <td>28.00</td>\n",
       "      <td>55.85</td>\n",
       "      <td>43785.90</td>\n",
       "      <td>...</td>\n",
       "      <td>2432.55</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>24.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>587.63</td>\n",
       "      <td>0.05</td>\n",
       "      <td>19.13</td>\n",
       "      <td>30.72</td>\n",
       "      <td>11241.58</td>\n",
       "      <td>...</td>\n",
       "      <td>624.53</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>82.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>3155.83</td>\n",
       "      <td>0.02</td>\n",
       "      <td>44.71</td>\n",
       "      <td>70.59</td>\n",
       "      <td>141084.24</td>\n",
       "      <td>...</td>\n",
       "      <td>7838.01</td>\n",
       "      <td>9</td>\n",
       "      <td>59</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>150.41</td>\n",
       "      <td>0.15</td>\n",
       "      <td>6.50</td>\n",
       "      <td>23.14</td>\n",
       "      <td>977.69</td>\n",
       "      <td>...</td>\n",
       "      <td>54.32</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>28.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>564.33</td>\n",
       "      <td>0.06</td>\n",
       "      <td>16.09</td>\n",
       "      <td>35.08</td>\n",
       "      <td>9078.38</td>\n",
       "      <td>...</td>\n",
       "      <td>504.35</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>498 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      loc  v(g)  ev(g)  iv(g)      n        v     l      d      i          e  \\\n",
       "0     1.1   1.4    1.4    1.4    1.3     1.30  1.30   1.30   1.30       1.30   \n",
       "1     1.0   1.0    1.0    1.0    1.0     1.00  1.00   1.00   1.00       1.00   \n",
       "2    24.0   5.0    1.0    3.0   63.0   309.13  0.11   9.50  32.54    2936.77   \n",
       "3    20.0   4.0    4.0    2.0   47.0   215.49  0.06  16.00  13.47    3447.89   \n",
       "4    24.0   6.0    6.0    2.0   72.0   346.13  0.06  17.33  19.97    5999.58   \n",
       "..    ...   ...    ...    ...    ...      ...   ...    ...    ...        ...   \n",
       "493  47.0   3.0    1.0    3.0  256.0  1563.78  0.04  28.00  55.85   43785.90   \n",
       "494  24.0   4.0    3.0    3.0  107.0   587.63  0.05  19.13  30.72   11241.58   \n",
       "495  82.0  11.0    3.0   10.0  475.0  3155.83  0.02  44.71  70.59  141084.24   \n",
       "496  10.0   2.0    1.0    1.0   32.0   150.41  0.15   6.50  23.14     977.69   \n",
       "497  28.0   6.0    5.0    5.0  104.0   564.33  0.06  16.09  35.08    9078.38   \n",
       "\n",
       "     ...        t  lOCode  lOComment  lOBlank  locCodeAndComment  uniq_Op  \\\n",
       "0    ...     1.30       2          2        2                  2      1.2   \n",
       "1    ...     1.00       1          1        1                  1      1.0   \n",
       "2    ...   163.15       1          0        6                  0     15.0   \n",
       "3    ...   191.55       0          0        3                  0     16.0   \n",
       "4    ...   333.31       0          0        3                  0     16.0   \n",
       "..   ...      ...     ...        ...      ...                ...      ...   \n",
       "493  ...  2432.55       2         13        2                  0     23.0   \n",
       "494  ...   624.53       1          7        4                  0     22.0   \n",
       "495  ...  7838.01       9         59       35                  0     32.0   \n",
       "496  ...    54.32       1         12        4                  0     13.0   \n",
       "497  ...   504.35       2          7        0                  0     20.0   \n",
       "\n",
       "     uniq_Opnd  total_Op  total_Opnd  branchCount  \n",
       "0          1.2       1.2         1.2          1.4  \n",
       "1          1.0       1.0         1.0          1.0  \n",
       "2         15.0      44.0        19.0          9.0  \n",
       "3          8.0      31.0        16.0          7.0  \n",
       "4         12.0      46.0        26.0         11.0  \n",
       "..         ...       ...         ...          ...  \n",
       "493       46.0     144.0       112.0          5.0  \n",
       "494       23.0      67.0        40.0          7.0  \n",
       "495       68.0     285.0       190.0         21.0  \n",
       "496       13.0      19.0        13.0          3.0  \n",
       "497       23.0      67.0        37.0         11.0  \n",
       "\n",
       "[498 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f86ae744-fe66-4dc1-83fa-80ae6338ef5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      False\n",
       "1       True\n",
       "2      False\n",
       "3      False\n",
       "4      False\n",
       "       ...  \n",
       "493     True\n",
       "494     True\n",
       "495     True\n",
       "496     True\n",
       "497     True\n",
       "Name: defects, Length: 498, dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f162e43-e561-4993-aa5a-8845a57a2271",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df2518d4-290a-4d48-9f0b-ae523c3d9c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCURACY, PRECISION, RECALL, AUC, F1 = [], [], [], [], []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9e6568-64a0-4d2c-9e56-be511bb7d48c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Random forest algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b362807b-d4eb-452d-9c0c-69dc959d766a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "ACCURACY.append(accuracy)\n",
    "\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "PRECISION.append(precision)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "RECALL.append(recall)\n",
    "\n",
    "# Calculate f1 score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "F1.append(f1)\n",
    "\n",
    "auc = roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])\n",
    "AUC.append(auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41fa7bd-fc11-4f9e-90b0-f569d12d1b63",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## GaussianNB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c67e2e-65e0-4577-81b1-50c44c825ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "ACCURACY.append(accuracy)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "PRECISION.append(precision)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "RECALL.append(recall)\n",
    "\n",
    "\n",
    "# Calculate f1 score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "F1.append(f1)\n",
    "\n",
    "# Calculate AUC score\n",
    "auc = roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])\n",
    "AUC.append(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da15f09-e7fc-4b6e-a0fe-db3931df2f71",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## AdaBoostClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156f9228-91e0-4056-b062-a92b68e79ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = AdaBoostClassifier(n_estimators=100)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "ACCURACY.append(accuracy)\n",
    "# print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "PRECISION.append(precision)\n",
    "# print(\"Precision:\", precision)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "RECALL.append(recall)\n",
    "\n",
    "# print(\"Recall:\", recall)\n",
    "\n",
    "# Calculate f1 score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "F1.append(f1)\n",
    "# print(\"F1 Score:\", f1)\n",
    "\n",
    "# Calculate AUC score\n",
    "auc = roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])\n",
    "AUC.append(auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41f90ee-7d7c-4283-ba8d-2b5056d448d8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de4577a-ee26-4ecb-b3da-0adf8d4afdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lf = MLPClassifier(random_state=1, max_iter=300)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# print(\"Multi Layer Perceptron\\n\")\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "PRECISION.append(precision)\n",
    "ACCURACY.append(accuracy)\n",
    "# print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "# print(\"Precision:\", precision)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "RECALL.append(recall)\n",
    "\n",
    "# print(\"Recall:\", recall)\n",
    "\n",
    "# Calculate f1 score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "F1.append(f1)\n",
    "# print(\"F1 Score:\", f1)\n",
    "\n",
    "# Calculate AUC score\n",
    "auc = roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])\n",
    "AUC.append(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801f4790-4dba-403c-880a-571bc83ef00f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Kneighbourclassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d51222-8389-4a5f-8b41-85d685d3e6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=5, p=2, metric='minkowski')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# print(\"KNeighbors Classifier\\n\")\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "ACCURACY.append(accuracy)\n",
    "# print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "PRECISION.append(precision)\n",
    "# print(\"Precision:\", precision)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "RECALL.append(recall)\n",
    "# print(\"Recall:\", recall)\n",
    "\n",
    "# Calculate f1 score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "F1.append(f1)\n",
    "# print(\"F1 Score:\", f1)\n",
    "\n",
    "# Calculate AUC score\n",
    "auc = roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])\n",
    "AUC.append(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc1ca4e-d351-4f91-8b3f-f26b75a8034b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee9a07e-6795-43f4-9882-29311ef1bd7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Reshape, GlobalAveragePooling1D\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D\n",
    "\n",
    "input_shape = X_train.shape[1]\n",
    "\n",
    "model_m = Sequential()\n",
    "model_m.add(Reshape((input_shape, 1), input_shape=(input_shape,)))\n",
    "model_m.add(Conv1D(100, input_shape, activation='relu'))\n",
    "\n",
    "# model_m.add(Conv1D(100, 11, activation='relu'))\n",
    "# model_m.add(MaxPooling1D(1))\n",
    "# model_m.add(Conv1D(160, 3, activation='relu'))\n",
    "# model_m.add(Conv1D(160, 3, activation='relu'))\n",
    "model_m.add(GlobalAveragePooling1D())\n",
    "model_m.add(Dropout(0.5))\n",
    "model_m.add(Dense(1, activation='tanh'))\n",
    "##print(model_m.summary())\n",
    "model_m.compile(loss='binary_crossentropy',\n",
    "                optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "y_train.astype('float64')\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 64\n",
    "history = model_m.fit(X_train,\n",
    "                      y_train.astype('float64'),\n",
    "                      batch_size=BATCH_SIZE,\n",
    "                      epochs=EPOCHS,\n",
    "                      verbose=1)\n",
    "\n",
    "# print(model_m.summary())\n",
    "\n",
    "accuracies = history.history['accuracy']\n",
    "\n",
    "# Compute the average accuracy across all epochs\n",
    "avg_accuracy = sum(accuracies) / len(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56826ab-7501-42ef-a945-5efd55de6308",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_precision = sum(PRECISION) / len(PRECISION)\n",
    "avg_recall = sum(RECALL) / len(RECALL)\n",
    "avg_f1 = sum(F1) / len(F1)\n",
    "avg_auc = sum(AUC) / len(AUC)\n",
    "print(avg_auc, AUC)\n",
    "ACCURACY.append(avg_accuracy)\n",
    "PRECISION.append(avg_precision)\n",
    "RECALL.append(avg_recall)\n",
    "F1.append(avg_f1)\n",
    "AUC.append(avg_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959d850e-ae35-4ee0-a396-3e3339a1d29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_loc = ''\n",
    "\n",
    "rows = {'Algorithm': ['Random\\nForest', ' Gaussian NB', ' Adaboost', ' MLP', ' KNN', ' CNN'],\n",
    "        'Accuracy': ACCURACY,\n",
    "        'Precision': PRECISION,\n",
    "        'Recall': RECALL,\n",
    "        'F1': F1,\n",
    "        'AUC': AUC}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f65cd7-0c7b-4d9e-83dd-22c9e96b6542",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms  = ['Random Forest', ' Gaussian NB', ' Adaboost', ' MLP', ' KNN', ' CNN'] \n",
    "count = 0\n",
    "for algo in algorithms: \n",
    "    print(f'{algo}: {ACCURACY[count]} ,{PRECISION[count]}, {RECALL[count]}, {F1[count]}, {AUC[count]}')\n",
    "    count+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658d1257-8bef-4b9c-895b-55883e872bbd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## HHO optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "468f20f5-6645-4b29-bbab-d61704f1ce84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def levy_flight(dim):\n",
    "  # Generate Levy flight step size\n",
    "  sigma = 1 / (np.power(gamma(1 + 0.5).rvs(), 1 + 0.5))\n",
    "  u = np.random.uniform(0, 1e10)\n",
    "  v = np.random.normal(0, 1)\n",
    "  step = u * np.power(abs(v), (1 / (1 + 0.5)))\n",
    "  return sigma * np.sign(v) * np.power(abs(v), (1 + 0.5)) * step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "94ccadf7-4ab2-411d-abf2-e83f51f65ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hho(max_iter, population_size, dim, objective_function):\n",
    "  # Initialize hawk positions\n",
    "  hawks = np.random.uniform(0, 1, size=(population_size, dim))\n",
    "\n",
    "  # Fitness values\n",
    "  fitness = np.array([objective_function(hawk,X_train,y_train,y_test) for hawk in hawks])\n",
    "  best_fitness = np.min(fitness)\n",
    "  best_position = hawks[np.argmin(fitness)]\n",
    "\n",
    "  # Main loop\n",
    "  for iter in range(max_iter):\n",
    "    E = 2 - (iter / max_iter)  # Energy parameter (exploration vs exploitation)\n",
    "    K = np.random.uniform(0, 1)  # Probability of exploration or soft besiege\n",
    "    Q = np.random.uniform(-1, 1)  # Random jump strength during Levy flight\n",
    "\n",
    "    # Exploration phase\n",
    "    if K < 0.5 or abs(Q) < E:\n",
    "      # Levy flight\n",
    "      levy_steps = np.array([levy_flight(dim) for _ in range(population_size)])\n",
    "      hawks = hawks + 0.001 * levy_steps * (best_position - hawks)\n",
    "    \n",
    "    # Soft besiege (exploitation) phase\n",
    "    else:\n",
    "      # Average position of better half of the population\n",
    "      average_position = np.mean(hawks[fitness <= np.median(fitness)], axis=0)\n",
    "      distance_to_average = hawks - average_position\n",
    "\n",
    "      # Random jump based on a hawk's escaping energy\n",
    "      jump_strength = np.abs(Q * E * distance_to_average)\n",
    "      jump_direction = np.random.uniform(-1, 1, size=distance_to_average.shape)\n",
    "      hawks = hawks + jump_strength * jump_direction\n",
    "\n",
    "    # Handle boundary violations\n",
    "    hawks = np.clip(hawks, 0, 1)  # Assuming 0-1 bounds for hyperparameters\n",
    "\n",
    "    # Update fitness\n",
    "    fitness = np.array([objective_function(params=hawk,X_train=X_train,y_train=y_train,y_test=y_test) for hawk in hawks])\n",
    "    \n",
    "    # Update best\n",
    "    if np.min(fitness) < best_fitness:\n",
    "      best_fitness = np.min(fitness)\n",
    "      best_position = hawks[np.argmin(fitness)]\n",
    "\n",
    "  return best_position, best_fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d8bd6ef4-f4e4-43df-b012-c5d2ebbb9cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 1],\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth': [3, 5, 8],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0c296f64-ff73-448f-8d06-38373cb91d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(params, X_train, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Objective function to evaluate model performance for HHO hyperparameter tuning.\n",
    "    \n",
    "    Args:\n",
    "      params (dict): Dictionary containing hyperparameter values.\n",
    "      X_reduced (np.ndarray): Reduced features after feature selection.\n",
    "      y_train (np.ndarray): Training labels.\n",
    "      y_test (np.ndarray): Testing labels (assumed to be available in the outer scope).\n",
    "    \n",
    "    Returns:\n",
    "      float: Performance metric (e.g., accuracy score) of the model with given hyperparameters.\n",
    "    \"\"\"\n",
    "    print(f\"params:{params}\")\n",
    "    # Create the model with the provided hyperparameters\n",
    "    model = XGBClassifier(learning_rate=params[0],n_estimators=int(params[1]),max_depth=int(params[2]))  \n",
    "    \n",
    "    # Train the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the testing data\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Choose an appropriate performance metric (replace with your desired metric)\n",
    "    # Common choices include: accuracy_score, precision_score, recall_score, f1_score\n",
    "    performance = accuracy_score(y_test, predictions)\n",
    "    \n",
    "    return performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a2431b94-2074-4664-b0d8-8510669fb561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hho_hyperparameter_tuning(X_train, y, param_grid, max_iter=100, population_size=20):\n",
    "  # Perform HHO optimization\n",
    "  best_params, _ = hho(max_iter, population_size, len(param_grid), objective_function)\n",
    "  return best_params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5ccf8e83-c4df-4440-baa7-7c4701a5f9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params:[0.09589196 0.44102356 0.67819508]\n",
      "params:[0.15819328 0.04132819 0.22447686]\n",
      "params:[0.26786864 0.75120401 0.17335343]\n",
      "params:[0.16031783 0.45499933 0.3836903 ]\n",
      "params:[0.12643311 0.71809269 0.9293772 ]\n",
      "params:[0.85167482 0.00658283 0.99978889]\n",
      "params:[0.49161122 0.47246648 0.28576793]\n",
      "params:[0.60842092 0.21314384 0.31479448]\n",
      "params:[0.16256152 0.90178552 0.52795869]\n",
      "params:[0.15360847 0.56913177 0.86926622]\n",
      "params:[0.1317633  0.48734413 0.4443761 ]\n",
      "params:[0.9003704  0.82733511 0.84967525]\n",
      "params:[0.93260487 0.99262971 0.98580081]\n",
      "params:[0.30785317 0.58916606 0.77695961]\n",
      "params:[0.35516324 0.34484926 0.69639027]\n",
      "params:[0.11321201 0.97978468 0.288919  ]\n",
      "params:[0.48484405 0.8450961  0.31924569]\n",
      "params:[0.82629274 0.03891853 0.15651843]\n",
      "params:[0.2057223  0.78533161 0.45305828]\n",
      "params:[0.15936686 0.69898852 0.35428521]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (20,) (20,3) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m best_params \u001b[38;5;241m=\u001b[39m \u001b[43mhho_hyperparameter_tuning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m Print(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest params: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Train model with best hyperparameters\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[63], line 3\u001b[0m, in \u001b[0;36mhho_hyperparameter_tuning\u001b[1;34m(X_train, y, param_grid, max_iter, population_size)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhho_hyperparameter_tuning\u001b[39m(X_train, y, param_grid, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, population_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m):\n\u001b[0;32m      2\u001b[0m   \u001b[38;5;66;03m# Perform HHO optimization\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m   best_params, _ \u001b[38;5;241m=\u001b[39m \u001b[43mhho\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpopulation_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjective_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m best_params\n",
      "Cell \u001b[1;32mIn[60], line 20\u001b[0m, in \u001b[0;36mhho\u001b[1;34m(max_iter, population_size, dim, objective_function)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m K \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(Q) \u001b[38;5;241m<\u001b[39m E:\n\u001b[0;32m     18\u001b[0m   \u001b[38;5;66;03m# Levy flight\u001b[39;00m\n\u001b[0;32m     19\u001b[0m   levy_steps \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([levy_flight(dim) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(population_size)])\n\u001b[1;32m---> 20\u001b[0m   hawks \u001b[38;5;241m=\u001b[39m hawks \u001b[38;5;241m+\u001b[39m \u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlevy_steps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_position\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mhawks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Soft besiege (exploitation) phase\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m   \u001b[38;5;66;03m# Average position of better half of the population\u001b[39;00m\n\u001b[0;32m     25\u001b[0m   average_position \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(hawks[fitness \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmedian(fitness)], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (20,) (20,3) "
     ]
    }
   ],
   "source": [
    "best_params = hho_hyperparameter_tuning(X_train, y_train, param_grid)\n",
    "\n",
    "Print(f'best params: {best_params}')\n",
    "# Train model with best hyperparameters\n",
    "model = XGBClassifier()  # Replace with your classifier\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model performance\n",
    "predictions = model.predict(X_test)\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, predictions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44524abe-508e-457e-ab4c-74ad3575bc81",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## HHO test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6e40d8fa-89a9-43d0-b6ed-35efc324a595",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1,1],  # Adjust ranges as needed\n",
    "    'n_estimators': range(50, 200, 10),  # Ensure integers for n_estimators\n",
    "    'max_depth': range(3, 8)  # Adjust ranges as needed\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9732fb4b-fddf-4627-9bdb-9d0791b95031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(params, X_train, y_train, y_test, params_grid):\n",
    "  \"\"\"\n",
    "  Evaluates the performance of a model with hyperparameters from the HHO search.\n",
    "\n",
    "  Args:\n",
    "      params (list): A list of hyperparameter values from the current hawk position.\n",
    "      X_train (numpy.ndarray): The training data features.\n",
    "      y_train (numpy.ndarray): The training data labels.\n",
    "      y_test (numpy.ndarray): The testing data labels (for evaluation).\n",
    "      params_grid (dict): The dictionary defining the search space for each hyperparameter.\n",
    "\n",
    "  Returns:\n",
    "      float: The evaluation metric (e.g., accuracy) of the trained model.\n",
    "\n",
    "  Raises:\n",
    "      ValueError: If the number of hyperparameters in params doesn't match the grid.\n",
    "      KeyError: If a hyperparameter name in params is not found in the grid.\n",
    "  \"\"\"\n",
    "\n",
    "  # Check if the number of hyperparameters matches the grid\n",
    "  if len(params) != len(params_grid):\n",
    "      raise ValueError(\"Number of hyperparameters in params list does not match the grid.\")\n",
    "\n",
    "  # Extract hyperparameters from params based on grid keys\n",
    "  hyperparams = {}\n",
    "  for i, key in enumerate(params_grid):\n",
    "      try:\n",
    "          hyperparams[key] = params_grid[key][int(i)]  # Ensure integer for n_estimators\n",
    "      except (IndexError, ValueError):\n",
    "          raise ValueError(f\"Invalid hyperparameter value or index for '{key}'.\") from None\n",
    "\n",
    "  # Train the model with the extracted hyperparameters\n",
    "  try:\n",
    "      model = XGBClassifier(**hyperparams)\n",
    "      model.fit(X_train, y_train)\n",
    "  except Exception as e:\n",
    "      print(f\"Error training model with hyperparameters: {hyperparams}\")\n",
    "      raise e  # Re-raise the exception for further handling\n",
    "\n",
    "  # Evaluate the model performance on the test set (replace with your desired metric)\n",
    "  predictions = model.predict(X_test)\n",
    "  accuracy = accuracy_score(y_test, predictions)\n",
    "  return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3378ff3b-f39f-4916-a11c-631a1f732d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hho(max_iter, population_size, dim, objective_function, X_train, y_train, params_grid):\n",
    "  \"\"\"\n",
    "  Performs Harris Hawks Optimization (HHO) for hyperparameter tuning.\n",
    "\n",
    "  Args:\n",
    "      max_iter (int): The maximum number of iterations.\n",
    "      population_size (int): The number of hawks (candidate parameter sets) in the population.\n",
    "      dim (int): The number of hyperparameters to be tuned.\n",
    "      objective_function (function): The function to evaluate the fitness of a hawk (candidate parameter set).\n",
    "      X_train (numpy.ndarray): The training data features.\n",
    "      y_train (numpy.ndarray): The training data labels.\n",
    "      params_grid (dict): The dictionary defining the search space for each hyperparameter.\n",
    "\n",
    "  Returns:\n",
    "      tuple: A tuple containing the best hawk position (best hyperparameters) and its fitness value.\n",
    "  \"\"\"\n",
    "\n",
    "  hawks = np.random.uniform(0, 1, size=(population_size, dim))  # Initialize hawk positions\n",
    "\n",
    "  # Fitness calculation (consider using validation set for a more robust metric)\n",
    "  fitness = np.array([objective_function(hawk, X_train, y_train, y_test,params_grid) for hawk in hawks])\n",
    "  best_fitness = np.min(fitness)\n",
    "  best_position = hawks[np.argmin(fitness)]\n",
    "\n",
    "  E = 2  # Exploration vs. Exploitation parameter (adjust as needed)\n",
    "  K = np.random.uniform(0, 1, size=population_size)  # Randomness parameter\n",
    "\n",
    "  for iter in range(max_iter):\n",
    "    # Levy Flight (Exploration)\n",
    "    energy = 1 - (iter / max_iter)  # Update energy based on iteration\n",
    "    J = np.random.uniform(0, 1, size=population_size)\n",
    "    Levy_flight = np.array([levy_flight(dim) for _ in range(population_size)])\n",
    "\n",
    "    # Attack Strategy (Exploitation - Rabbit Hare Harmony)\n",
    "    attack_success_probability = np.random.uniform(0, 1, size=population_size)\n",
    "    change_probability = np.random.uniform(0, 1, size=population_size)\n",
    "\n",
    "    # Differential Movement (Medium Rabbit)\n",
    "    diff_rabbit = np.random.uniform(-1, 1, size=(population_size, dim))\n",
    "\n",
    "    # Levy Flight with Differential Movement (Levy Hare)\n",
    "    levy_rabbit = Levy_flight * J\n",
    "\n",
    "    # Update hawks using vectorized operations (avoids explicit reshaping)\n",
    "    # Ensure best_position has the same shape as a single hawk (population_size, dim)\n",
    "    best_position = best_position.reshape(1, -1)  # Reshape to match hawks\n",
    "    offset_vec = E * K * (best_position - hawks)  # Shape: (population_size, dim)\n",
    "    new_hawks = hawks + offset_vec + levy_rabbit * (hawks[fitness.argsort()] - hawks)\n",
    "\n",
    "    # Clipping (Ensure hawks stay within bounds)\n",
    "    new_hawks = np.clip(new_hawks, 0, 1)\n",
    "    hawks = np.where(hawks < new_hawks, new_hawks, hawks)\n",
    "\n",
    "    # Update fitness and best position\n",
    "    fitness = np.array([objective_function(hawk, X_train, y_train, y_test,params_grid) for hawk in hawks])\n",
    "    best_fitness = np.min(fitness)\n",
    "    best_position = hawks[np.argmin(fitness)]\n",
    "\n",
    "  return best_position, best_fitness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6844f615-d825-49cf-855d-3b3c9581205c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def levy_flight(dim):\n",
    "  sigma = 1 / (np.power(gamma(1 + 0.5).rvs(), 1 + 0.5))  # Sample from gamma distribution\n",
    "  u = np.random.uniform(0, 1e10)  # Large finite upper bound (adjust as needed)\n",
    "  v = np.random.normal(0, 1)\n",
    "  step = u * np.power(abs(v), (1 / (1 + 0.5)))\n",
    "  return step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2e447d26-0f9f-4305-a480-825c4f85b2ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (20,) (20,3) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[90], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Perform HHO optimization\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m best_params, _ \u001b[38;5;241m=\u001b[39m \u001b[43mhho\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpopulation_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mobjective_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobjective_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mparams_grid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Print the best hyperparameters found\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Hyperparameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_params)\n",
      "Cell \u001b[1;32mIn[88], line 47\u001b[0m, in \u001b[0;36mhho\u001b[1;34m(max_iter, population_size, dim, objective_function, X_train, y_train, params_grid)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Update hawks using vectorized operations (avoids explicit reshaping)\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Ensure best_position has the same shape as a single hawk (population_size, dim)\u001b[39;00m\n\u001b[0;32m     46\u001b[0m best_position \u001b[38;5;241m=\u001b[39m best_position\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Reshape to match hawks\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m offset_vec \u001b[38;5;241m=\u001b[39m \u001b[43mE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_position\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mhawks\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Shape: (population_size, dim)\u001b[39;00m\n\u001b[0;32m     48\u001b[0m new_hawks \u001b[38;5;241m=\u001b[39m hawks \u001b[38;5;241m+\u001b[39m offset_vec \u001b[38;5;241m+\u001b[39m levy_rabbit \u001b[38;5;241m*\u001b[39m (hawks[fitness\u001b[38;5;241m.\u001b[39margsort()] \u001b[38;5;241m-\u001b[39m hawks)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Clipping (Ensure hawks stay within bounds)\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (20,) (20,3) "
     ]
    }
   ],
   "source": [
    "# Perform HHO optimization\n",
    "best_params, _ = hho(max_iter=100, population_size=20, dim=len(param_grid),\n",
    "                     objective_function=objective_function, X_train=X_train, y_train=y_train,\n",
    "                     params_grid=param_grid)\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "model = XGBClassifier(learning_rate=best_params[0], n_estimators=int(best_params[1]), max_depth=int(best_params[2]))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model performance on the test set (replace with your desired evaluation)\n",
    "predictions = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b3b53b-1c11-4b62-9afa-9d9ff6c93d61",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## hho test 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb390644-dbc6-40e8-9f24-06f90e25f22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Best Fitness = 0.8866666666666667, Best Solution = {'n_estimators': 400.1777598643025, 'max_depth': 3.1328879602481363, 'learning_rate': 0.001, 'subsample': 0.5, 'colsample_bytree': 1.0, 'gamma': 1.0}\n",
      "Iteration 2: Best Fitness = 0.8866666666666667, Best Solution = {'n_estimators': 700.0512612618757, 'max_depth': 7.088677467572284, 'learning_rate': 0.001, 'subsample': 0.64630535284898, 'colsample_bytree': 0.5768185006175857, 'gamma': 1.0}\n",
      "Iteration 3: Best Fitness = 0.8866666666666667, Best Solution = {'n_estimators': 299.6763022490097, 'max_depth': 6.917319494747035, 'learning_rate': 0.18658696834628247, 'subsample': 1.0, 'colsample_bytree': 0.5, 'gamma': 0.7721258367463127}\n",
      "Iteration 4: Best Fitness = 0.8933333333333333, Best Solution = {'n_estimators': 599.9575924647065, 'max_depth': 6.003760102274936, 'learning_rate': 0.001, 'subsample': 0.5324304814522207, 'colsample_bytree': 0.6236729928710705, 'gamma': 0.9812446286178117}\n",
      "Iteration 5: Best Fitness = 0.8933333333333333, Best Solution = {'n_estimators': 499.8774873497141, 'max_depth': 6.095328079138346, 'learning_rate': 0.001, 'subsample': 0.713159866560486, 'colsample_bytree': 0.6043270385177265, 'gamma': 1.0}\n",
      "Iteration 6: Best Fitness = 0.8933333333333333, Best Solution = {'n_estimators': 600.0278623042883, 'max_depth': 4.006700786599309, 'learning_rate': 0.001, 'subsample': 0.7484305393039806, 'colsample_bytree': 0.5124275857151974, 'gamma': 0.6830175842422023}\n",
      "Iteration 7: Best Fitness = 0.88, Best Solution = {'n_estimators': 200.12231281804802, 'max_depth': 5.173068400401706, 'learning_rate': 0.001, 'subsample': 0.6157400048189697, 'colsample_bytree': 0.8343472717249991, 'gamma': 0.7886797248428703}\n",
      "Iteration 8: Best Fitness = 0.88, Best Solution = {'n_estimators': 100.0, 'max_depth': 3.0, 'learning_rate': 0.001, 'subsample': 0.8847593024121134, 'colsample_bytree': 0.7251408743650904, 'gamma': 0.45631039707842747}\n",
      "Iteration 9: Best Fitness = 0.8866666666666667, Best Solution = {'n_estimators': 700.2476661416188, 'max_depth': 8.899815073188217, 'learning_rate': 0.3, 'subsample': 0.8755953736801843, 'colsample_bytree': 0.6194076817947509, 'gamma': 1.0}\n",
      "Iteration 10: Best Fitness = 0.8933333333333333, Best Solution = {'n_estimators': 499.9958973093799, 'max_depth': 5.92545991396904, 'learning_rate': 0.001, 'subsample': 0.5472668880642676, 'colsample_bytree': 0.8440116670457883, 'gamma': 0.869959472234455}\n",
      "Optimization finished.\n",
      "Best solution: {'n_estimators': 499.9958973093799, 'max_depth': 5.92545991396904, 'learning_rate': 0.001, 'subsample': 0.5472668880642676, 'colsample_bytree': 0.8440116670457883, 'gamma': 0.869959472234455}\n",
      "Best fitness: 0.8933333333333333\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Define fitness function\n",
    "def fitness_function(hyperparameters):\n",
    "    hyperparameters = {key: int(value) if key in ['n_estimators', 'max_depth'] else value for key, value in hyperparameters.items()}\n",
    "\n",
    "    # Initialize XGBClassifier with given hyperparameters\n",
    "    \n",
    "    model = XGBClassifier(**hyperparameters)\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "# Define search space for hyperparameters\n",
    "search_space = {\n",
    "    'n_estimators': range(100, 1000, 100),\n",
    "    'max_depth': range(3, 10),\n",
    "    'learning_rate': np.linspace(0.001, 0.3, 10),\n",
    "    'subsample': np.linspace(0.5, 1, 5),\n",
    "    'colsample_bytree': np.linspace(0.5, 1, 5),\n",
    "    'gamma': np.linspace(0, 1, 5)\n",
    "}\n",
    "\n",
    "# Define HHO parameters\n",
    "population_size = 20\n",
    "max_iterations = 10\n",
    "\n",
    "# Initialize population of solutions (harmony vectors)\n",
    "def initialize_population(search_space, population_size):\n",
    "    population = []\n",
    "    for _ in range(population_size):\n",
    "        solution = {}\n",
    "        for param, values in search_space.items():\n",
    "            solution[param] = np.random.choice(values)\n",
    "        population.append(solution)\n",
    "    return population\n",
    "\n",
    "# Define harmony search operator\n",
    "def harmony_search(harmony, search_space):\n",
    "    new_harmony = {}\n",
    "    for param, value in harmony.items():\n",
    "        if np.random.rand() < 0.5:\n",
    "            new_harmony[param] = np.random.choice(search_space[param])\n",
    "        else:\n",
    "            new_harmony[param] = value\n",
    "    return new_harmony\n",
    "\n",
    "# Define hawks optimization operator\n",
    "def hawks_optimization(hawk, search_space):\n",
    "    new_hawk = {}\n",
    "    for param, value in hawk.items():\n",
    "        new_hawk[param] = value + np.random.normal(0, 0.1)\n",
    "        new_hawk[param] = np.clip(new_hawk[param], min(search_space[param]), max(search_space[param]))\n",
    "    return new_hawk\n",
    "\n",
    "# Main HHO optimization loop\n",
    "population = initialize_population(search_space, population_size)\n",
    "for iteration in range(max_iterations):\n",
    "    for i in range(len(population)):\n",
    "        # Apply harmony search operator\n",
    "        population[i] = harmony_search(population[i], search_space)\n",
    "        # Apply hawks optimization operator\n",
    "        population[i] = hawks_optimization(population[i], search_space)\n",
    "    \n",
    "    # Evaluate fitness of each solution\n",
    "    fitness_scores = [fitness_function(solution) for solution in population]\n",
    "    \n",
    "    # Update best solution\n",
    "    best_solution_index = np.argmax(fitness_scores)\n",
    "    best_solution = population[best_solution_index]\n",
    "    best_fitness = fitness_scores[best_solution_index]\n",
    "    \n",
    "    print(f\"Iteration {iteration+1}: Best Fitness = {best_fitness}, Best Solution = {best_solution}\")\n",
    "\n",
    "print(\"Optimization finished.\")\n",
    "print(\"Best solution:\", best_solution)\n",
    "print(\"Best fitness:\", best_fitness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ad292c-3df5-4937-9430-266572dccab4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de8a33e-db1e-43e4-9279-d9a21d8849f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48aa9cc1-3183-4adb-90a5-e292cd0d66d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d952d37-7307-410a-80c2-3af80f9034ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7d071c-b37e-4a66-9efa-aee0a13a3205",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce090484-da5f-4c14-8b19-1ab74134b86d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1b63ea-a93c-45d0-9b1e-691482fead22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbada606-ad81-404e-9efd-ca1737be5cb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c37ad1c3-db42-44e6-811b-6de6e6257f93",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## gpt test code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4b97431f-496c-483f-ae20-89ae35187dbe",
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "value -0.337229 for Parameter learning_rate should be greater equal to 0\nlearning_rate: Learning rate(step size) of update.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 61\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m best_params\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m best_params \u001b[38;5;241m=\u001b[39m \u001b[43mhho_optimizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_hawks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_dimensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Parameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_params)\n",
      "Cell \u001b[1;32mIn[48], line 25\u001b[0m, in \u001b[0;36mhho_optimizer\u001b[1;34m(x_train, y_train, num_hawks, num_dimensions, max_iter)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhho_optimizer\u001b[39m(x_train, y_train, num_hawks, num_dimensions, max_iter):\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m# Initialize hawks' population\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     hawks_position \u001b[38;5;241m=\u001b[39m initialize(num_hawks, num_dimensions)\n\u001b[1;32m---> 25\u001b[0m     hawks_fitness \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_fitness\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhawks_position\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# Main loop\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_iter):\n\u001b[0;32m     29\u001b[0m         \u001b[38;5;66;03m# Update the position of each hawk\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[48], line 15\u001b[0m, in \u001b[0;36mcalculate_fitness\u001b[1;34m(hawks, x_train, y_train)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m params \u001b[38;5;129;01min\u001b[39;00m hawks:\n\u001b[0;32m     13\u001b[0m     xgb_clf \u001b[38;5;241m=\u001b[39m XGBClassifier(max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(params[\u001b[38;5;241m0\u001b[39m]), learning_rate\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;241m1\u001b[39m], \n\u001b[0;32m     14\u001b[0m                             n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(params[\u001b[38;5;241m2\u001b[39m]), gamma\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;241m3\u001b[39m])\n\u001b[1;32m---> 15\u001b[0m     \u001b[43mxgb_clf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m xgb_clf\u001b[38;5;241m.\u001b[39mpredict(x_train)\n\u001b[0;32m     17\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_train, y_pred)\n",
      "File \u001b[1;32m~\\.conda\\envs\\Material\\lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\Material\\lib\\site-packages\\xgboost\\sklearn.py:1490\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1462\u001b[0m (\n\u001b[0;32m   1463\u001b[0m     model,\n\u001b[0;32m   1464\u001b[0m     metric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1469\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1470\u001b[0m )\n\u001b[0;32m   1471\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1472\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[0;32m   1473\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1487\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[0;32m   1488\u001b[0m )\n\u001b[1;32m-> 1490\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1495\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1498\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1501\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[0;32m   1505\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\.conda\\envs\\Material\\lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\Material\\lib\\site-packages\\xgboost\\training.py:189\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 189\u001b[0m bst \u001b[38;5;241m=\u001b[39m \u001b[43mcb_container\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mafter_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m evals_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    192\u001b[0m     evals_result\u001b[38;5;241m.\u001b[39mupdate(cb_container\u001b[38;5;241m.\u001b[39mhistory)\n",
      "File \u001b[1;32m~\\.conda\\envs\\Material\\lib\\site-packages\\xgboost\\callback.py:167\u001b[0m, in \u001b[0;36mCallbackContainer.after_training\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, Booster), msg\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_cv:\n\u001b[1;32m--> 167\u001b[0m     num_parallel_tree, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_get_booster_layer_trees\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model\u001b[38;5;241m.\u001b[39mattr(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_score\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    169\u001b[0m         model\u001b[38;5;241m.\u001b[39mbest_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(cast(\u001b[38;5;28mstr\u001b[39m, model\u001b[38;5;241m.\u001b[39mattr(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_score\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n",
      "File \u001b[1;32m~\\.conda\\envs\\Material\\lib\\site-packages\\xgboost\\core.py:1475\u001b[0m, in \u001b[0;36m_get_booster_layer_trees\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_booster_layer_trees\u001b[39m(model: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBooster\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]:\n\u001b[0;32m   1470\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get number of trees added to booster per-iteration.  This function will be removed\u001b[39;00m\n\u001b[0;32m   1471\u001b[0m \u001b[38;5;124;03m    once `best_ntree_limit` is dropped in favor of `best_iteration`.  Returns\u001b[39;00m\n\u001b[0;32m   1472\u001b[0m \u001b[38;5;124;03m    `num_parallel_tree` and `num_groups`.\u001b[39;00m\n\u001b[0;32m   1473\u001b[0m \n\u001b[0;32m   1474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1475\u001b[0m     config \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1476\u001b[0m     booster \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearner\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgradient_booster\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1477\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m booster \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\.conda\\envs\\Material\\lib\\site-packages\\xgboost\\core.py:1732\u001b[0m, in \u001b[0;36mBooster.save_config\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1730\u001b[0m json_string \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_char_p()\n\u001b[0;32m   1731\u001b[0m length \u001b[38;5;241m=\u001b[39m c_bst_ulong()\n\u001b[1;32m-> 1732\u001b[0m \u001b[43m_check_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterSaveJsonConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1733\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1734\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1735\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_string\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1736\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m json_string\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1737\u001b[0m result \u001b[38;5;241m=\u001b[39m json_string\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39mdecode()  \u001b[38;5;66;03m# pylint: disable=no-member\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\Material\\lib\\site-packages\\xgboost\\core.py:279\u001b[0m, in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[0;32m    269\u001b[0m \n\u001b[0;32m    270\u001b[0m \u001b[38;5;124;03mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m    return value from API calls\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[38;5;241m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[1;31mXGBoostError\u001b[0m: value -0.337229 for Parameter learning_rate should be greater equal to 0\nlearning_rate: Learning rate(step size) of update."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Function to initialize hawks' population\n",
    "def initialize(num_hawks, num_dimensions):\n",
    "    return np.random.uniform(low=-1, high=1, size=(num_hawks, num_dimensions))\n",
    "\n",
    "# Function to calculate fitness (accuracy in this case)\n",
    "def calculate_fitness(hawks, x_train, y_train):\n",
    "    fitness = []\n",
    "    for params in hawks:\n",
    "        xgb_clf = XGBClassifier(max_depth=int(params[0]), learning_rate=params[1], \n",
    "                                n_estimators=int(params[2]), gamma=params[3])\n",
    "        xgb_clf.fit(x_train, y_train)\n",
    "        y_pred = xgb_clf.predict(x_train)\n",
    "        accuracy = accuracy_score(y_train, y_pred)\n",
    "        fitness.append(accuracy)\n",
    "    return np.array(fitness)\n",
    "\n",
    "# Function for Harris Hawks Optimization\n",
    "def hho_optimizer(x_train, y_train, num_hawks, num_dimensions, max_iter):\n",
    "    # Initialize hawks' population\n",
    "    hawks_position = initialize(num_hawks, num_dimensions)\n",
    "    hawks_fitness = calculate_fitness(hawks_position, x_train, y_train)\n",
    "    \n",
    "    # Main loop\n",
    "    for t in range(max_iter):\n",
    "        # Update the position of each hawk\n",
    "        for i in range(num_hawks):\n",
    "            E0 = 2 * np.random.rand() - 1  # Random number in [-1, 1]\n",
    "            E = 2 * E0 * (1 - (t / max_iter))  # Modified E based on the iteration\n",
    "            hawks_position[i] += E * np.random.rand() * (hawks_fitness[i] - np.mean(hawks_fitness))\n",
    "        \n",
    "        # Clipping the positions to the feasible space\n",
    "        hawks_position = np.clip(hawks_position, -1, 1)\n",
    "        \n",
    "        # Calculate fitness for the updated positions\n",
    "        hawks_fitness_new = calculate_fitness(hawks_position, x_train, y_train)\n",
    "        \n",
    "        # Update the hawks' position and fitness\n",
    "        for i in range(num_hawks):\n",
    "            if hawks_fitness_new[i] > hawks_fitness[i]:\n",
    "                hawks_fitness[i] = hawks_fitness_new[i]\n",
    "            else:\n",
    "                # Random exploration\n",
    "                r = np.random.rand()\n",
    "                if r < 0.5:\n",
    "                    hawks_position[i] = np.random.uniform(low=-1, high=1, size=num_dimensions)\n",
    "                else:\n",
    "                    # Spiral\n",
    "                    hawks_position[i] += np.random.rand() * (hawks_fitness[i] - np.mean(hawks_fitness))\n",
    "        \n",
    "    # Find the best hawk\n",
    "    best_hawk_index = np.argmax(hawks_fitness)\n",
    "    best_params = hawks_position[best_hawk_index]\n",
    "    \n",
    "    return best_params\n",
    "\n",
    "# Example usage\n",
    "best_params = hho_optimizer(X_train, y_train, num_hawks=10, num_dimensions=4, max_iter=100)\n",
    "print(\"Best Parameters:\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8ac016-2a48-4d44-ba5f-0b6958ba8313",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e65c6a6-55d9-4a5f-b3f6-95d4e161cb9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
